{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20ed501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import sys\n",
    "from transformers import Wav2Vec2Processor, HubertForCTC\n",
    "import torch\n",
    "import torchaudio\n",
    "from datasets import load_dataset\n",
    "from IPython.display import Audio\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2923fd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract audio from video\n",
    "\n",
    "# def convert_video_to_audio_ffmpeg(video_file, output_ext=\"mp3\"):\n",
    "#     filename, ext = os.path.splitext(video_file)\n",
    "#     subprocess.call([\"ffmpeg\", \"-y\", \"-i\", video_file, f\"{filename}.{output_ext}\"], \n",
    "#                     stdout=subprocess.DEVNULL,\n",
    "#                     stderr=subprocess.STDOUT)\n",
    "#convert_video_to_audio_ffmpeg('/home/delta/Downloads/youtube_tutorial_automation.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f98b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n",
    "model = HubertForCTC.from_pretrained(\"facebook/hubert-large-ls960-ft\").to('cuda') #change to 'cpu' if no Nvidia graphic card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8092c589",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = '/home/delta/Downloads/youtube_tutorial_automation.mp3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e409cb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_offset, num_frames = 0, 16000*60*4  # num_frames depends on GPU size\n",
    "number_of_frames = torchaudio.load(audio_file)[0].shape[1]\n",
    "number_of_chunks = int(number_of_frames/num_frames)\n",
    "remaining = number_of_frames % num_frames\n",
    "transcriptions = ''\n",
    "for i in range(number_of_chunks):\n",
    "    data_waveform, rate_of_sample = torchaudio.load(audio_file,frame_offset=num_frames*i, num_frames=num_frames)\n",
    "    transform = torchaudio.transforms.Resample(rate_of_sample, 16000)\n",
    "    data_waveform = transform(data_waveform)\n",
    "    inputs = processor(data_waveform[0], sampling_rate=16000, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs.to('cuda')).logits\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = processor.batch_decode(predicted_ids)\n",
    "    transcription = transcription[0].lower()\n",
    "    transcriptions += transcription\n",
    "\n",
    "data_waveform, rate_of_sample = torchaudio.load(audio_file,frame_offset=num_frames*(i+1), num_frames=remaining)\n",
    "transform = torchaudio.transforms.Resample(rate_of_sample, 16000)\n",
    "data_waveform = transform(data_waveform)\n",
    "inputs = processor(data_waveform[0], sampling_rate=16000, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs.to('cuda')).logits\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "transcription = processor.batch_decode(predicted_ids)\n",
    "transcription = transcription[0].lower()\n",
    "transcriptions += transcription\n",
    "transcriptions = re.sub(' +', ' ', transcriptions)\n",
    "print(transcriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2addca52",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
