{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c227813e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from Config import conf\n",
    "from transformers import T5Tokenizer\n",
    "from torchtext.nn.modules.multiheadattention import ScaledDotProduct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76ba0a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = conf()\n",
    "h = config.h\n",
    "N = config.N\n",
    "dmodel = config.dmodel\n",
    "dk= config.dk\n",
    "dv = config.dv\n",
    "dff = config.dff\n",
    "tokenizer = T5Tokenizer.from_pretrained(config.tokenizer_path)\n",
    "max_length = config.max_length\n",
    "vocab_size = config.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fb858ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1input = 'I love dog'\n",
    "sentence2input = 'I love cat'\n",
    "sentence1output = 'I am a man'\n",
    "sentence2output = 'I am a women'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c565b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_input = tokenizer.batch_encode_plus([sentence1input,sentence2input],\n",
    "                                          max_length= max_length,\n",
    "                                          truncation=True,\n",
    "                                          return_tensors='pt'\n",
    "                                         )\n",
    "batch_output = tokenizer.batch_encode_plus([sentence1output,sentence2output],\n",
    "                                           max_length= max_length, \n",
    "                                           truncation=True,\n",
    "                                           return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "341d3247",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout, max_len, vocab_size):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.embedded_layer = nn.Embedding(vocab_size,d_model)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedded_layer(x)\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba7ee8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleAttentionHead(nn.Module):\n",
    "    def __init__(self,dmodel,dk,dv,cuda_number='cuda:0'):\n",
    "        super(SingleAttentionHead,self).__init__()\n",
    "        self.proj_key = nn.Linear(dmodel,dk).to(cuda_number)\n",
    "        self.proj_query = nn.Linear(dmodel,dk).to(cuda_number)\n",
    "        self.proj_value  = nn.Linear(dmodel,dv).to(cuda_number)\n",
    "        self.dk = dk\n",
    "        self.cuda_number = cuda_number\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = x.to(self.cuda_number)\n",
    "        k = self.proj_key(x)\n",
    "        q = self.proj_query(x)\n",
    "        v = self.proj_value(x)\n",
    "        head = torch.matmul(F.softmax(torch.matmul(q,k.transpose(-2,-1))/(self.dk**0.5)),v)\n",
    "        if self.cuda_number != 'cuda:0':\n",
    "            return head.to('cuda:0')\n",
    "        return head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bfcf747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiAttentionHead(nn.Module):\n",
    "    def __init__(self,dmodel,dk,dv,max_length):\n",
    "        super(MultiAttentionHead, self).__init__()\n",
    "        \n",
    "        nlayers_GPU_0 = int(h/2)\n",
    "        nlayers_GPU_1 = int(h/2)\n",
    "        \n",
    "        self.head_GPU0 = nn.ModuleList([\n",
    "            SingleAttentionHead(dmodel,dk,dv,'cuda:0') for i in range(nlayers_GPU_0)\n",
    "        ])\n",
    "        \n",
    "        self.head_GPU1 = nn.ModuleList([\n",
    "            SingleAttentionHead(dmodel,dk,dv,'cuda:1') for i in range(nlayers_GPU_1)\n",
    "        ])\n",
    "        #Weight_0 layer:\n",
    "        self.W0 = nn.Linear(dmodel,dmodel).to('cuda:0')   #Size h*dv x dmodel. But since dv = dk and dk x h = dv so it's a dmodel x dmodel layer -> cuda:0\n",
    "        #LayerNormalisation\n",
    "        self.Add_and_Nom = nn.LayerNorm(dmodel, eps=1e-05, elementwise_affine=True).to('cuda:0')\n",
    "        self.dropout = nn.Dropout(0.1).to('cuda:0')\n",
    "    \n",
    "    def forward(self,x):\n",
    "        multi_attention_heads = 'Empty'\n",
    "        for i, l in enumerate(self.head_GPU0):\n",
    "            if i == 0:\n",
    "                multi_attention_heads = l(x)\n",
    "            else:\n",
    "                multi_attention_heads = torch.cat((multi_attention_heads,l(x)), dim=2)\n",
    "        for i, l in enumerate(self.head_GPU1):\n",
    "            multi_attention_heads = torch.cat((multi_attention_heads,l(x)), dim=2)\n",
    "        multi_attention_heads = self.W0(multi_attention_heads) \n",
    "        multi_attention_heads = self.Add_and_Nom(x + multi_attention_heads)  #cuda:0\n",
    "        multi_attention_heads = self.dropout(multi_attention_heads)\n",
    "        return multi_attention_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9074858e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderStack(nn.Module):\n",
    "    def __init__(self,dmodel,dk,dv,max_length,vocab_size):\n",
    "        super(EncoderStack, self).__init__()\n",
    "        self.multiAttentionHeads = MultiAttentionHead(dmodel,dk,dv,max_length)\n",
    "        self.lin1a = nn.Linear(dmodel,dff).to('cuda:0')\n",
    "        self.dropout1 = nn.Dropout(0.1).to('cuda:0')\n",
    "        self.lin1b = nn.Linear(dff,dmodel).to('cuda:0')\n",
    "        self.Add_and_Nom = nn.LayerNorm(dmodel, eps=1e-05, elementwise_affine=True).to('cuda:0')\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.multiAttentionHeads(x)\n",
    "        sublayer_x = self.lin1a(x)\n",
    "        sublayer_x = F.relu(sublayer_x)\n",
    "        sublayer_x = self.dropout1(sublayer_x)\n",
    "        sublayer_x = self.lin1b(sublayer_x)\n",
    "        sublayer_x = self.Add_and_Nom(x + sublayer_x)\n",
    "        return sublayer_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "14e68e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderTransformerStacks(nn.Module):\n",
    "    def __init__(self,dmodel,dk,dv,max_length,vocab_size):\n",
    "        super(EncoderTransformerStacks, self).__init__()\n",
    "        self.encoderStack = nn.ModuleList([\n",
    "            EncoderStack(dmodel,dk,dv,max_length,vocab_size) for i in range(6)\n",
    "        ])\n",
    "\n",
    "    def forward(self,x):\n",
    "        for i, l in enumerate(self.encoderStack):\n",
    "            x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef2c8042",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderTransformer(nn.Module):\n",
    "    def __init__(self,dmodel,dk,dv,max_length,vocab_size):\n",
    "        super(EncoderTransformer, self).__init__()\n",
    "        self.positionEncoder = PositionalEncoding(dmodel,0.1, max_length,vocab_size).to('cuda:0')\n",
    "        self.encoder_Stacks = EncoderTransformerStacks(dmodel,dk,dv,max_length,vocab_size)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.positionEncoder(x)\n",
    "        x = self.encoder_Stacks(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b45d57f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "input_ids = batch_input['input_ids'].to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2555a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "Encode = EncoderTransformer(dmodel,dk,dv,max_length,vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91bdee14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 4])\n",
      "tensor([[[ 1.5872,  0.1189, -0.7779, -0.9281],\n",
      "         [ 0.0652, -1.2639,  1.5158, -0.3172],\n",
      "         [-1.5286,  1.0462, -0.2345,  0.7169],\n",
      "         [ 1.7295, -0.4886, -0.6089, -0.6320]],\n",
      "\n",
      "        [[-1.1638,  1.5459,  0.1112, -0.4934],\n",
      "         [ 1.6073, -0.1452, -1.1350, -0.3271],\n",
      "         [-1.5900,  0.8782,  0.8288, -0.1169],\n",
      "         [ 0.9621, -0.1697,  0.7724, -1.5649]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    }
   ],
   "source": [
    "out = Encode(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ae1b9a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_0_Memory_Allocated = torch.cuda.memory_reserved(0)\n",
    "GPU_1_Memory_Allocated = torch.cuda.memory_reserved(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dfc19428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used in GPU:0 0.06 GB\n",
      "Memory used in GPU:1 0.21 GB\n"
     ]
    }
   ],
   "source": [
    "print('Memory used in GPU:0', round((GPU_0_Memory_Allocated)/100000000,2),'GB')\n",
    "print('Memory used in GPU:1', round((GPU_1_Memory_Allocated)/10000000,2),'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a039fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "783eae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "efbb2492",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_output_ids = batch_output['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "282d959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_output_attention_mask = batch_output['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "970dd2ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27, 183,   3,   9, 388,   1],\n",
       "        [ 27, 183,   3,   9, 887,   1]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_output_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "599e391f",
   "metadata": {},
   "outputs": [],
   "source": [
    "positional_embedding = PositionalEncoding(dmodel,0.1,max_length,vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a1ce49b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_decoder_inputs = positional_embedding(batch_output_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cad5d689",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_project = nn.Linear(dmodel,dk)\n",
    "q_project = nn.Linear(dmodel,dk)\n",
    "v_project = nn.Linear(dmodel,dk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6e622846",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(pre_decoder_inputs.size(0)):\n",
    "    decode_output = pre_decoder_inputs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dcd1b8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 4])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fcd6c524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2431,  1.2010, -0.2413,  0.7864],\n",
       "        [ 0.9482,  1.4963,  0.0165,  0.0000],\n",
       "        [ 1.7246,  2.5453,  2.0686,  0.1869],\n",
       "        [ 0.7949,  2.3445,  0.3388, -0.1423],\n",
       "        [-1.3277,  0.0000, -0.9949,  0.9949],\n",
       "        [-1.4374,  1.2929, -1.1703,  1.7299]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_decoder_inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0a15f4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k1: tensor([[-0.9401],\n",
      "        [ 0.2234],\n",
      "        [ 1.0020],\n",
      "        [ 0.0553],\n",
      "        [-0.9540],\n",
      "        [-1.6868]], grad_fn=<AddmmBackward>)\n",
      "\n",
      "q1 tensor([[-0.0353],\n",
      "        [-0.6907],\n",
      "        [-0.8605],\n",
      "        [-0.4546],\n",
      "        [-0.2535],\n",
      "        [-0.2723]], grad_fn=<AddmmBackward>)\n",
      "\n",
      "v1 tensor([[-0.0813],\n",
      "        [-0.5412],\n",
      "        [-1.0388],\n",
      "        [-0.5946],\n",
      "        [ 0.0930],\n",
      "        [-0.0417]], grad_fn=<AddmmBackward>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = k_project(pre_decoder_inputs[0])\n",
    "q = q_project(pre_decoder_inputs[0])\n",
    "v = v_project(pre_decoder_inputs[0])\n",
    "print('k1:',k)\n",
    "print('')\n",
    "print('q1',q)\n",
    "print('')\n",
    "print('v1',v)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "973c8eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0331,  0.6493,  0.8090,  0.4274,  0.2383,  0.2560],\n",
       "        [-0.0079, -0.1543, -0.1923, -0.1016, -0.0566, -0.0608],\n",
       "        [-0.0353, -0.6921, -0.8622, -0.4556, -0.2540, -0.2729],\n",
       "        [-0.0019, -0.0382, -0.0476, -0.0251, -0.0140, -0.0151],\n",
       "        [ 0.0336,  0.6589,  0.8209,  0.4337,  0.2418,  0.2598],\n",
       "        [ 0.0595,  1.1651,  1.4515,  0.7669,  0.4276,  0.4593]],\n",
       "       grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_QT = torch.matmul(k,q.transpose(0,1))\n",
    "k_QT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4f95a487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_size = q.size(0)\n",
    "mask = (torch.triu(torch.ones(q_size, q_size)) == 1).transpose(0, 1)\n",
    "mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a48f1e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0331,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "        [-0.0079, -0.1543,    -inf,    -inf,    -inf,    -inf],\n",
       "        [-0.0353, -0.6921, -0.8622,    -inf,    -inf,    -inf],\n",
       "        [-0.0019, -0.0382, -0.0476, -0.0251,    -inf,    -inf],\n",
       "        [ 0.0336,  0.6589,  0.8209,  0.4337,  0.2418,    -inf],\n",
       "        [ 0.0595,  1.1651,  1.4515,  0.7669,  0.4276,  0.4593]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked = k_QT + mask\n",
    "masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "61a7d636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49543f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a87b8d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cc74307f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0331,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "        [-0.0079, -0.1543,    -inf,    -inf,    -inf,    -inf],\n",
       "        [-0.0353, -0.6921, -0.8622,    -inf,    -inf,    -inf],\n",
       "        [-0.0019, -0.0382, -0.0476, -0.0251,    -inf,    -inf],\n",
       "        [ 0.0336,  0.6589,  0.8209,  0.4337,  0.2418,    -inf],\n",
       "        [ 0.0595,  1.1651,  1.4515,  0.7669,  0.4276,  0.4593]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d59251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
