{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "T5_Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "1ZNonVfI6cw9jKd2IrkpY0TVpLkhaUnL0",
      "authorship_tag": "ABX9TyNQ2+QmczCYvUYTzjy9AuJV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d244869c11e7435e9305feb8ab688d8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a38435cb31b4433c99b7b60b6a55f124",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0edb7568215d4a0297275bf27b39694d",
              "IPY_MODEL_d3477dfe56d34d43bfd07015f64a4ab9"
            ]
          }
        },
        "a38435cb31b4433c99b7b60b6a55f124": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0edb7568215d4a0297275bf27b39694d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6554b6ec2d43444cae9b192880bdf6ec",
            "_dom_classes": [],
            "description": "Epoch: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f8c9b67a17c4143a358efae738af4ca"
          }
        },
        "d3477dfe56d34d43bfd07015f64a4ab9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_383e2b92017c4078aa946b5c032f80a6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [51:26&lt;00:00, 3086.55s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_77d3dc7c7b444e25a961b67820b25ab0"
          }
        },
        "6554b6ec2d43444cae9b192880bdf6ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f8c9b67a17c4143a358efae738af4ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "383e2b92017c4078aa946b5c032f80a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "77d3dc7c7b444e25a961b67820b25ab0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "74dbb3242b33408582362adc303d987a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dfebc7c1a64245488fa5fda393b3e35a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_98cb74e7f05548ccb64ec5b30f8995b8",
              "IPY_MODEL_af40d09ef0f643ea87ea6e926a5b41a6"
            ]
          }
        },
        "dfebc7c1a64245488fa5fda393b3e35a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "98cb74e7f05548ccb64ec5b30f8995b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e5bd8d3b5f684f92bee99df6aef17ac3",
            "_dom_classes": [],
            "description": "Iteration: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 26280,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 26280,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_416769a0dc824ab49b3afc083ad34d11"
          }
        },
        "af40d09ef0f643ea87ea6e926a5b41a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bd59a3bfe4de43dfa9bcc8283380af69",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 26280/26280 [51:26&lt;00:00,  8.51it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_408294e16d704d91a39a57d6aa3ba4cc"
          }
        },
        "e5bd8d3b5f684f92bee99df6aef17ac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "416769a0dc824ab49b3afc083ad34d11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd59a3bfe4de43dfa9bcc8283380af69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "408294e16d704d91a39a57d6aa3ba4cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "381e6e61aded4ad590c31fa634c3cd62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8486e82d4def486c97a52474a3928122",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_320ecd8b3871482084a7db0e4a3773e2",
              "IPY_MODEL_3bd6b1e2b767435a937655a6f2147948"
            ]
          }
        },
        "8486e82d4def486c97a52474a3928122": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "320ecd8b3871482084a7db0e4a3773e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0a3abd8ac9114fa7bb264b248c5462b8",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 548,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 548,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5a10b949fe424b8fadb7b62a1096a05d"
          }
        },
        "3bd6b1e2b767435a937655a6f2147948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_32061d03a6cc42fa9ef5fb14898bcbb0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 548/548 [01:47&lt;00:00,  5.11it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8c110511be1c4abdb802527383128c0b"
          }
        },
        "0a3abd8ac9114fa7bb264b248c5462b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5a10b949fe424b8fadb7b62a1096a05d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "32061d03a6cc42fa9ef5fb14898bcbb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8c110511be1c4abdb802527383128c0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dentadelta/123/blob/master/T5_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Pt9heQqcUM4",
        "colab_type": "text"
      },
      "source": [
        "# I borrows  a few lines of codes from the below Google Colabs:\n",
        "\n",
        "https://colab.research.google.com/github/patil-suraj/exploring-T5/blob/master/T5_on_TPU.ipynb#scrollTo=coOmS2s_xDBy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbPHvi2vcf_u",
        "colab_type": "code",
        "outputId": "e1f76971-3dab-4df4-d04e-7bd3af2baa29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install nlp transformers\n",
        "!pip install pyarrow==0.17"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nlp in /usr/local/lib/python3.6/dist-packages (0.2.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.11.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from nlp) (4.41.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from nlp) (0.3.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from nlp) (1.18.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from nlp) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from nlp) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from nlp) (0.7)\n",
            "Requirement already satisfied: pyarrow>=0.16.0 in /usr/local/lib/python3.6/dist-packages (from nlp) (0.17.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: pyarrow==0.17 in /usr/local/lib/python3.6/dist-packages (0.17.0)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from pyarrow==0.17) (1.18.4)\n",
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/c7/8bf2c62c3f133f45e135a8a116e4e0f162043248e3db54de30996eaf1a8a/wandb-0.8.36-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 3.5MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/f9/c315aa88e51fabdc08e91b333cfefb255aff04a2ee96d632c32cb19180c9/GitPython-3.1.3-py3-none-any.whl (451kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 18.4MB/s \n",
            "\u001b[?25hCollecting watchdog>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/c3/ed6d992006837e011baca89476a4bbffb0a91602432f73bd4473816c76e2/watchdog-0.10.2.tar.gz (95kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 10.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.352.0)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.8.1)\n",
            "Collecting gql==0.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/c4/6f/cf9a3056045518f06184e804bae89390eb706168349daa9dff8ac609962a/gql-0.2.0.tar.gz\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.1.2)\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/95/9a20eebcedab2c1c63fad59fe19a0469edfc2a25b8576497e8084629c2ff/sentry_sdk-0.14.4-py2.py3-none-any.whl (104kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 16.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.12.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.23.0)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/6b/01baa293090240cf0562cc5eccb69c6f5006282127f2b846fad011305c79/configparser-5.0.0-py3-none-any.whl\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 9.7MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.1MB/s \n",
            "\u001b[?25hCollecting pathtools>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Collecting graphql-core<2,>=0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/89/00ad5e07524d8c523b14d70c685e0299a8b0de6d0727e368c41b89b7ed0b/graphql-core-1.1.tar.gz (70kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from gql==0.2.0->wandb) (2.3)\n",
            "Requirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (2.9)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: watchdog, gql, subprocess32, pathtools, graphql-core\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for watchdog: filename=watchdog-0.10.2-cp36-none-any.whl size=73605 sha256=746bf0e6deec8c8050a2749e40ea64b5ebcb90775c6ceb2a28899cd2d6009fe7\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/ed/6c/028dea90d31b359cd2a7c8b0da4db80e41d24a59614154072e\n",
            "  Building wheel for gql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gql: filename=gql-0.2.0-cp36-none-any.whl size=7630 sha256=55c023f9b140e24a1f7ea8ccf48059dafc240c0324fe55be33148b4d77cca553\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/0e/7b/58a8a5268655b3ad74feef5aa97946f0addafb3cbb6bd2da23\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp36-none-any.whl size=6489 sha256=0b78b456117ca713154ab5a9a4b8d0df35e450bd45f4db672cf45ef66814857f\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8784 sha256=07c22a8ec915a99936c8ec52b24023699fd24501d8ab5e519997ff4ef01bbb09\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "  Building wheel for graphql-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for graphql-core: filename=graphql_core-1.1-cp36-none-any.whl size=104650 sha256=b26bf845692f55aa0ac76afb98194b82175000693caea3d2a6331ec4b126e729\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/99/d7/c424029bb0fe910c63b68dbf2aa20d3283d023042521bcd7d5\n",
            "Successfully built watchdog gql subprocess32 pathtools graphql-core\n",
            "Installing collected packages: shortuuid, smmap, gitdb, GitPython, pathtools, watchdog, docker-pycreds, graphql-core, gql, sentry-sdk, configparser, subprocess32, wandb\n",
            "Successfully installed GitPython-3.1.3 configparser-5.0.0 docker-pycreds-0.4.0 gitdb-4.0.5 gql-0.2.0 graphql-core-1.1 pathtools-0.1.2 sentry-sdk-0.14.4 shortuuid-1.0.1 smmap-3.0.4 subprocess32-3.5.4 wandb-0.8.36 watchdog-0.10.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTnFET4CckwS",
        "colab_type": "text"
      },
      "source": [
        "## Make Sure You Restart Your Runtime After Running the Above Codes\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYtD-WU2cii_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pyarrow as pa\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "from transformers import (T5Config, T5Tokenizer, T5ForConditionalGeneration, TextDataset, DataCollator, Trainer, TrainingArguments)\n",
        "import ipywidgets as widgets\n",
        "import random\n",
        "from typing import Dict, List\n",
        "import nlp\n",
        "from dataclasses import dataclass\n",
        "from tqdm.auto import tqdm\n",
        "import re\n",
        "import pathlib\n",
        "import numpy as np\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "@dataclass\n",
        "class T2TDataCollator(DataCollator):\n",
        "    def collate_batch(self, batch: List) -> Dict[str, torch.Tensor]:\n",
        "        input_ids = torch.stack([example['input_ids'] for example in batch])\n",
        "        lm_labels = torch.stack([example['target_ids'] for example in batch])\n",
        "        lm_labels[lm_labels[:, :] == 0] = -100\n",
        "        attention_mask = torch.stack([example['attention_mask'] for example in batch])\n",
        "        decoder_attention_mask = torch.stack([example['target_attention_mask'] for example in batch])\n",
        "        \n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids, \n",
        "            'attention_mask': attention_mask,\n",
        "            'lm_labels': lm_labels, \n",
        "            'decoder_attention_mask': decoder_attention_mask\n",
        "        }\n",
        "\n",
        "class Custom_T5_Training():\n",
        "  def __init__(self, dataset_path,working_folder, maximum_input_length, maximum_output_length, epochs=1, logging_step=1000, model_name = 't5-base'):\n",
        "    self.dataset_path = dataset_path\n",
        "    self.working_folder = working_folder\n",
        "    self.model_name = model_name\n",
        "    self.maximum_input_length = maximum_input_length\n",
        "    self.maximum_output_length = maximum_output_length\n",
        "    self.epochs = epochs\n",
        "    self.load_data()\n",
        "    self.load_model()\n",
        "    self.training_args = TrainingArguments(\n",
        "                        output_dir= self.working_folder,\n",
        "                        overwrite_output_dir=True,\n",
        "                        do_train=True,\n",
        "                        do_eval =True,\n",
        "                        num_train_epochs=self.epochs,   \n",
        "                        per_device_train_batch_size=                1, \n",
        "                        logging_steps=                              logging_step,   \n",
        "                        save_steps=                                 -1,\n",
        "                        )\n",
        "\n",
        "  def load_data(self):\n",
        "    file = pathlib.Path('{}/train_data.pt'.format(self.working_folder))\n",
        "    if file.exists():\n",
        "      self.train_dataset = torch.load('{}/train_data.pt'.format(self.working_folder))\n",
        "      self.valid_dataset = torch.load('{}/valid_data.pt'.format(self.working_folder))\n",
        "      self.test_dataset =  torch.load('{}/test_data.pt'.format(self.working_folder))\n",
        "\n",
        "      self.tokenizer = T5Tokenizer.from_pretrained(self.working_folder)\n",
        "    else:\n",
        "      self.create_dataset()\n",
        "\n",
        "  def load_model(self):\n",
        "    file = pathlib.Path('{}/pytorch_model.bin'.format(self.working_folder))\n",
        "    if file.exists():\n",
        "      self.model = T5ForConditionalGeneration.from_pretrained(self.working_folder)\n",
        "    \n",
        "    else:\n",
        "      config = T5Config.from_pretrained(self.model_name)\n",
        "      self.model = T5ForConditionalGeneration.from_pretrained(self.model_name, config=config)\n",
        "\n",
        "  def train_model(self, epochs=1):\n",
        "    data_collator = T2TDataCollator()\n",
        "    progress = widgets.FloatProgress(value=0.1, min=0.0, max=1.0, bar_style = 'info')\n",
        "\n",
        "    trainer = Trainer(\n",
        "                        model= self.model,\n",
        "                        args=self.training_args,\n",
        "                        data_collator=data_collator,\n",
        "                        train_dataset=self.train_dataset,\n",
        "                        eval_dataset =self.test_dataset,\n",
        "                        prediction_loss_only=True\n",
        "                      )\n",
        "    \n",
        "    progress.value = 0.4\n",
        "    p_start, p_end = 0.4, 1.\n",
        "    \n",
        "    def progressify(f):\n",
        "      def inner(*args, **kwargs):\n",
        "        if trainer.epoch is not None:\n",
        "          progress.value = p_start + trainer.epoch / self.epochs * (p_end - p_start)\n",
        "          return f(*args, **kwargs)\n",
        "      return inner\n",
        "\n",
        "    try:\n",
        "      trainer._training_step = progressify(trainer._training_step)\n",
        "      trainer.train()\n",
        "    \n",
        "    except KeyboardInterrupt:\n",
        "      print('Keyboard interrupted, but dont worry because...')\n",
        "    finally:\n",
        "      trainer.save_model(self.working_folder)\n",
        "      print('the model has been saved')\n",
        "\n",
        "  def add_eos_to_examples(self,example):\n",
        "    example['input_text'] = '<{}>: <{}> </s>'.format(example['prefix'] , example['input_text'] )\n",
        "    example['target_text'] = '\"<{}> </s>\"'.format(example['target_text'])\n",
        "    return example\n",
        "\n",
        "  def convert_to_features(self,example_batch):\n",
        "    input_encodings = self.tokenizer.batch_encode_plus(example_batch['input_text'], pad_to_max_length=True, max_length=self.maximum_input_length)     ########## Specify the maximum input lengths (context + question)\n",
        "    target_encodings = self.tokenizer.batch_encode_plus(example_batch['target_text'], pad_to_max_length=True, max_length=self.maximum_output_length)     ########## Specify the maximum output length\n",
        "    encodings = {\n",
        "        'input_ids': input_encodings['input_ids'], \n",
        "        'attention_mask': input_encodings['attention_mask'],\n",
        "        'target_ids': target_encodings['input_ids'],\n",
        "        'target_attention_mask': target_encodings['attention_mask']\n",
        "    }\n",
        "    return encodings\n",
        "\n",
        "  def create_dataset(self):\n",
        "    self.tokenizer = T5Tokenizer.from_pretrained(self.model_name)\n",
        "    df = pd.read_csv(self.dataset_path)\n",
        "    df_train, df_valid, df_test= np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])\n",
        "\n",
        "    fields = [\n",
        "          ('input_text', pa.string()),\n",
        "          ('target_text', pa.string()),\n",
        "          ('prefix', pa.string())\n",
        "      ]\n",
        "\n",
        "    train_dataset = nlp.arrow_dataset.Dataset(pa.Table.from_pandas(df_train,pa.schema(fields)))\n",
        "    valid_dataset = nlp.arrow_dataset.Dataset(pa.Table.from_pandas(df_valid,pa.schema(fields)))\n",
        "    test_dataset  = nlp.arrow_dataset.Dataset(pa.Table.from_pandas(df_test,pa.schema(fields)))\n",
        "\n",
        "    train_dataset = train_dataset.map(self.add_eos_to_examples)\n",
        "    train_dataset = train_dataset.map(self.convert_to_features, batched=True)\n",
        "\n",
        "    valid_dataset = valid_dataset.map(self.add_eos_to_examples, load_from_cache_file=False)\n",
        "    valid_dataset = valid_dataset.map(self.convert_to_features, batched=True, load_from_cache_file=False)\n",
        "\n",
        "    test_dataset = test_dataset.map(self.add_eos_to_examples, load_from_cache_file=False)\n",
        "    test_dataset = test_dataset.map(self.convert_to_features, batched=True, load_from_cache_file=False)\n",
        "\n",
        "    columns = ['input_ids', 'target_ids', 'attention_mask', 'target_attention_mask']\n",
        "    train_dataset.set_format(type='torch', columns=columns)\n",
        "    valid_dataset.set_format(type='torch', columns=columns)\n",
        "    test_dataset.set_format(type='torch', columns=columns)\n",
        "\n",
        "    torch.save(train_dataset, '{}/train_data.pt'.format(self.working_folder))\n",
        "    torch.save(valid_dataset, '{}/valid_data.pt'.format(self.working_folder))\n",
        "    torch.save(test_dataset, '{}/test_data.pt'.format(self.working_folder))\n",
        "\n",
        "    self.train_dataset = train_dataset\n",
        "    self.valid_dataset = valid_dataset\n",
        "    self.test_dataset = test_dataset\n",
        "    self.tokenizer.save_pretrained(self.working_folder)\n",
        "\n",
        "  def validate_model(self, dataset = None, batch_size=32):\n",
        "    if dataset is None:\n",
        "      dataset = self.valid_dataset\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n",
        "    evaluate_model = T5ForConditionalGeneration.from_pretrained(self.working_folder).to(device)\n",
        "    try:\n",
        "      answers = []\n",
        "\n",
        "      for batch in tqdm(dataloader):\n",
        "        outs = evaluate_model.generate(input_ids=batch['input_ids'].to(device), \n",
        "                        attention_mask=batch['attention_mask'].to(device),\n",
        "                        early_stopping=True)\n",
        "        outs = [self.tokenizer.decode(ids) for ids in outs]\n",
        "        answers.extend(outs)\n",
        "    except KeyboardInterrupt:\n",
        "      print('proceeds to evaluation')\n",
        "\n",
        "    finally:\n",
        "      predictions = []\n",
        "      references = []\n",
        "      input_texts = []\n",
        "      for ref, pred in zip(dataset, answers):\n",
        "        pred = pred[4:]\n",
        "        predictions.append(pred)\n",
        "        \n",
        "        input_ = self.tokenizer.decode(ref['input_ids'])\n",
        "        input_ = ''.join(input_)\n",
        "        input_ = re.sub('[!@#$*-]', '', input_)\n",
        "        input_ = input_.lstrip().title()\n",
        "\n",
        "        start_index = input_.index('>:')\n",
        "        prefix = input_[:start_index]\n",
        "        input_ = input_[start_index + 6:]\n",
        "\n",
        "        input_texts.append(input_)\n",
        "\n",
        "        output_ = self.tokenizer.decode(ref['target_ids'])\n",
        "        output_ = ''.join(output_)[4:-3]\n",
        "        references.append(output_)\n",
        "    \n",
        "      for _ in range(min(10, len(answers))):\n",
        "        i = random.randint(0, len(predictions))\n",
        "        print('Input:             {}\\nPredicted Answer:  {}\\nReal Answer:       {}\\n'.format(input_texts[i],predictions[i], references[i]))\n",
        "\n",
        "      return {'input_text': input_texts, 'target_text': predictions}\n",
        "\n",
        "\n",
        "  def work(self, file_path, batch_size = 100):\n",
        "    file = pathlib.Path('{}/work_data.pt'.format(self.working_folder))\n",
        "    if file.exists():\n",
        "      work_dataset = torch.load('{}/train_data.pt'.format(self.working_folder))\n",
        "      self.tokenizer = T5Tokenizer.from_pretrained(self.working_folder)\n",
        "    else:\n",
        "      da = pd.read_csv(file_path)\n",
        "      da['target_text'] = ''\n",
        "      fields = [\n",
        "          ('input_text', pa.string()),\n",
        "          ('target_text', pa.string()),\n",
        "          ('prefix', pa.string())\n",
        "      ]\n",
        "\n",
        "      work_dataset = nlp.arrow_dataset.Dataset(pa.Table.from_pandas(da,pa.schema(fields)))\n",
        "      work_dataset = work_dataset.map(self.add_eos_to_examples)\n",
        "      work_dataset = work_dataset.map(self.convert_to_features, batched=True)\n",
        "      columns = ['input_ids', 'target_ids', 'attention_mask', 'target_attention_mask']\n",
        "      work_dataset.set_format(type='torch', columns=columns)\n",
        "      torch.save(work_dataset, '{}/work_data.pt'.format(self.working_folder))\n",
        "      self.tokenizer.save_pretrained(self.working_folder)\n",
        "    \n",
        "    results = self.validate_model(work_dataset, batch_size=batch_size)\n",
        "    ds = pd.DataFrame(results)\n",
        "  \n",
        "    ds.to_csv('{}/work_output.csv'.format(self.working_folder), index=None)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lp9BLBtIcrl4",
        "colab_type": "text"
      },
      "source": [
        "# Run Your Own Model Here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5yh9YTIczhZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "My_T5 = Custom_T5_Training(\n",
        "    dataset_path= 'https://www.dropbox.com/s/6w5z4qvt8vytngm/training_data.csv?dl=1', # Try to put your data on your personal cloud database (as an url) so that you can keep training the model using the latest available data\n",
        "    working_folder= '/content/',   # Change this to you google drive so that you dont have to retrain your own model from scratch in the future\n",
        "    maximum_input_length=512,\n",
        "    maximum_output_length= 60,\n",
        "    model_name= 't5-base',\n",
        "    logging_step = 100,\n",
        "    epochs = 1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gq5HTmRngcqb",
        "colab_type": "text"
      },
      "source": [
        " Uncomment and run the below function if you updated your dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YokP9bPFgEWU",
        "colab_type": "code",
        "outputId": "63183334-8932-47f4-869a-af621b7238e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "#My_T5.create_dataset()  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "52559it [00:01, 52210.78it/s]\n",
            "100%|██████████| 53/53 [00:17<00:00,  2.97it/s]\n",
            "17520it [00:00, 50764.71it/s]\n",
            "100%|██████████| 18/18 [00:05<00:00,  3.06it/s]\n",
            "17520it [00:00, 48899.43it/s]\n",
            "100%|██████████| 18/18 [00:05<00:00,  3.07it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZrMNAqSc2vx",
        "colab_type": "code",
        "outputId": "2a43568e-06ce-41d0-c799-61bb8ff6e5cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359,
          "referenced_widgets": [
            "d244869c11e7435e9305feb8ab688d8b",
            "a38435cb31b4433c99b7b60b6a55f124",
            "0edb7568215d4a0297275bf27b39694d",
            "d3477dfe56d34d43bfd07015f64a4ab9",
            "6554b6ec2d43444cae9b192880bdf6ec",
            "1f8c9b67a17c4143a358efae738af4ca",
            "383e2b92017c4078aa946b5c032f80a6",
            "77d3dc7c7b444e25a961b67820b25ab0",
            "74dbb3242b33408582362adc303d987a",
            "dfebc7c1a64245488fa5fda393b3e35a",
            "98cb74e7f05548ccb64ec5b30f8995b8",
            "af40d09ef0f643ea87ea6e926a5b41a6",
            "e5bd8d3b5f684f92bee99df6aef17ac3",
            "416769a0dc824ab49b3afc083ad34d11",
            "bd59a3bfe4de43dfa9bcc8283380af69",
            "408294e16d704d91a39a57d6aa3ba4cc"
          ]
        }
      },
      "source": [
        "My_T5.train_model()   # you can interrup training anytime and the model will be saved"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d244869c11e7435e9305feb8ab688d8b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='i…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74dbb3242b33408582362adc303d987a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=26280.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{\"loss\": 2.4776219486892224, \"learning_rate\": 4.619482496194825e-05, \"epoch\": 0.076103500761035, \"step\": 2000}\n",
            "{\"loss\": 2.434477653712034, \"learning_rate\": 4.2389649923896504e-05, \"epoch\": 0.15220700152207, \"step\": 4000}\n",
            "{\"loss\": 2.4032016327381136, \"learning_rate\": 3.8584474885844754e-05, \"epoch\": 0.228310502283105, \"step\": 6000}\n",
            "{\"loss\": 2.4020297024846076, \"learning_rate\": 3.4779299847793e-05, \"epoch\": 0.30441400304414, \"step\": 8000}\n",
            "{\"loss\": 2.3949736602306366, \"learning_rate\": 3.097412480974125e-05, \"epoch\": 0.380517503805175, \"step\": 10000}\n",
            "{\"loss\": 2.3567006936371326, \"learning_rate\": 2.71689497716895e-05, \"epoch\": 0.45662100456621, \"step\": 12000}\n",
            "{\"loss\": 2.3792035594284533, \"learning_rate\": 2.3363774733637747e-05, \"epoch\": 0.532724505327245, \"step\": 14000}\n",
            "{\"loss\": 2.3893420217037202, \"learning_rate\": 1.9558599695585997e-05, \"epoch\": 0.60882800608828, \"step\": 16000}\n",
            "{\"loss\": 2.3774873881340026, \"learning_rate\": 1.5753424657534248e-05, \"epoch\": 0.684931506849315, \"step\": 18000}\n",
            "{\"loss\": 2.34460402405262, \"learning_rate\": 1.1948249619482495e-05, \"epoch\": 0.76103500761035, \"step\": 20000}\n",
            "{\"loss\": 2.3300615413188934, \"learning_rate\": 8.143074581430746e-06, \"epoch\": 0.837138508371385, \"step\": 22000}\n",
            "{\"loss\": 2.3743771876990794, \"learning_rate\": 4.337899543378996e-06, \"epoch\": 0.91324200913242, \"step\": 24000}\n",
            "{\"loss\": 2.352931753754616, \"learning_rate\": 5.327245053272451e-07, \"epoch\": 0.989345509893455, \"step\": 26000}\n",
            "\n",
            "\n",
            "the model has been saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdest6sBc6C-",
        "colab_type": "code",
        "outputId": "6b4e7e08-22dd-44e0-f214-a066c05251b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "381e6e61aded4ad590c31fa634c3cd62",
            "8486e82d4def486c97a52474a3928122",
            "320ecd8b3871482084a7db0e4a3773e2",
            "3bd6b1e2b767435a937655a6f2147948",
            "0a3abd8ac9114fa7bb264b248c5462b8",
            "5a10b949fe424b8fadb7b62a1096a05d",
            "32061d03a6cc42fa9ef5fb14898bcbb0",
            "8c110511be1c4abdb802527383128c0b"
          ]
        }
      },
      "source": [
        "_ = My_T5.validate_model()  # Validating on dataset the model has never seen before"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "381e6e61aded4ad590c31fa634c3cd62",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=548.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Input:             What Is The Term For The Line Across The Field Where The Ball Is Positioned Before\n",
            "Predicted Answer:  the ball>\n",
            "Real Answer:       line of scrimmage\n",
            "\n",
            "Input:             What Can Sometimes Be Translated As Tetragraph?>\n",
            "Predicted Answer:  the tetragraph>\n",
            "Real Answer:       Square-Block Characters\n",
            "\n",
            "Input:             Which Term For His Religious Outlook Did Popper Prefer?>\n",
            "Predicted Answer:  the sacramental>\n",
            "Real Answer:       agnosticism\n",
            "\n",
            "Input:             Where Did Hanna Holborn Gray Go After Yale?>\n",
            "Predicted Answer:  St. Louis>\n",
            "Real Answer:       University of Chicago\n",
            "\n",
            "Input:             What Particles Are Pushed Through The Antenna By A Transmitter?>\n",
            "Predicted Answer:  sea particles>\n",
            "Real Answer:       electrons\n",
            "\n",
            "Input:             What Did Japan Call The Occupied Group Of Asian Nations?>\n",
            "Predicted Answer:  the \"Asian\">\n",
            "Real Answer:       Greater East Asia Co-Prosperity Sphere\n",
            "\n",
            "Input:             How Many Mortgage Lenders Went Bankrupt During 2007 And 2008?>\n",
            "Predicted Answer:  five>\n",
            "Real Answer:       Over 100\n",
            "\n",
            "Input:             What Nfl Team Played At The Yale Bowl From 19731974?>\n",
            "Predicted Answer:  The New York Yankees>\n",
            "Real Answer:       New York Giants\n",
            "\n",
            "Input:             What Size Of Choirs Have Performed Gustav Mahler'S 1906 Symphony No. 8\n",
            "Predicted Answer:  two>\n",
            "Real Answer:       over 400\n",
            "\n",
            "Input:             Which Islands Decided To Return To British Rule After Receiving Independence?>\n",
            "Predicted Answer:  British and British>\n",
            "Real Answer:       Anguilla and the Turks and Caicos\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OW7REvsgdnPp",
        "colab_type": "text"
      },
      "source": [
        "I removed the 'context\" from the dataset so that I can use the dataset as a sequence to sequence model, not as a question to answer model. This explains why the predicted answers are not accurate. \n",
        "\n",
        "Nevertheless T5 is the state of the art NLP model. \n",
        "\n",
        "If you need to train a question to answer model, you needs to use a Long Form pretrained model (not a T5 model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdK1vp_-eNR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "My_T5.work('PATH_TO_REAL_WORLD_DATASET_FOR_THE_MACHINE_TO CARRYOUT_AN_ANALYSIS.csv',1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFQBZkTzWUXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}