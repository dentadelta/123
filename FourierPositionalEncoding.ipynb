{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FourierPositionalEncoding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNQ1DIGfehW8IoNzsrV/Gaf"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9wDarB2SY4t"
      },
      "source": [
        "%%capture\n",
        "!pip install einops"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7cc2b1cOJN5"
      },
      "source": [
        "from torchvision.io import read_image\n",
        "from einops import rearrange, reduce\n",
        "import torch\n",
        "import math\n",
        "from torchvision.transforms import transforms\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddwo7hq9ONmP"
      },
      "source": [
        "Batch_Size = 5\n",
        "Image_Height = 224\n",
        "Image_Width = 224\n",
        "K = 4\n",
        "dmodel = 512"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEQGq8PuOQOh",
        "outputId": "f460b303-6a3e-41b7-f40c-a2e1b5cf2201"
      },
      "source": [
        "# Create a fake batch image. Will use actual images later to see if the network can learn.For now, lets create the model first\n",
        "batch_image = torch.rand(Batch_Size,3,Image_Height,Image_Width)\n",
        "print(batch_image.size())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3, 224, 224])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj4X5AMGOR1N"
      },
      "source": [
        "def normaliseImage(bm):\n",
        "  #Normalise the image:\n",
        "  mean, std = bm.mean([2,3]), bm.std([2,3])\n",
        "  i = 0\n",
        "  for m,s in zip(mean,std):\n",
        "      normaliser = transforms.Normalize(m, s)\n",
        "      normalised_image = normaliser(bm[i])\n",
        "      scale = max(abs(normalised_image.max()),abs(normalised_image.min()))\n",
        "      bm[i] = normalised_image/scale\n",
        "      i += 1\n",
        "  return reduce(bm,'b c h w -> b h w', 'mean')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPwB5JhoO5zA"
      },
      "source": [
        "def fourier_encoder(batch_image,K=7):\n",
        "    m = 256    \n",
        "    pe = torch.rand(batch_image.size(0),batch_image.size(1),batch_image.size(2),4*K + 1) \n",
        "    band_frequency = torch.logspace(start=1, end= m/2,steps=K,base=2,dtype=torch.float64)\n",
        "    x_normalised_coordinate = torch.linspace(start=-1, end=1,steps=batch_image.size(1),dtype=torch.float64)\n",
        "    y_normalised_coordinate = torch.linspace(start=-1, end=1,steps=batch_image.size(2),dtype=torch.float64)\n",
        "    b = 0\n",
        "    for b in range(batch_image.size(0)):\n",
        "        x = 0\n",
        "        for i in x_normalised_coordinate:\n",
        "            angle_x = i*math.pi*band_frequency\n",
        "            angle_y = torch.einsum('i,j -> ij',y_normalised_coordinate,band_frequency)*math.pi\n",
        "            pe[b][x][:,-1] = batch_image[b][x]\n",
        "            pe[b][x][:,0:2*K:2] = angle_x.sin()\n",
        "            pe[b][x][:,1:2*K:2] = angle_x.cos()\n",
        "            pe[b][x][:,2*K:4*K:2] = angle_y.sin()\n",
        "            pe[b][x][:,2*K + 1:4*K:2] = angle_y.cos()\n",
        "            x += 1\n",
        "    return rearrange(pe,'b h w c -> b (h w) c')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgBV3WtlOU7P"
      },
      "source": [
        "batch_image = normaliseImage(batch_image)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu7mk5axO15N"
      },
      "source": [
        "batch_image = fourier_encoder(batch_image,K)\n",
        "latent_array = fourier_encoder(torch.rand(Batch_Size,32,32),K)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MshZEJI_POlo"
      },
      "source": [
        "to_q = torch.nn.Linear(K*4+1,dmodel)  #29 = 4*4 + 1; 512 is the dmodel dimension\n",
        "to_k = torch.nn.Linear(K*4+1,dmodel)\n",
        "to_v = torch.nn.Linear(K*4+1,dmodel)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nie2u6-1ekV3"
      },
      "source": [
        "q = to_q(latent_array)\n",
        "k = to_k(batch_image)\n",
        "v = to_v(batch_image)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RU3ZfbSfBQP"
      },
      "source": [
        "I = torch.einsum('b i d , b j d -> b i j', q, k)/dmodel**0.5    # actual not dmodel**0.5 but dk**05. However since we only use one layer dmodel = dk = 512"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZTQ-fc-fW-h"
      },
      "source": [
        "weight = torch.nn.functional.softmax(I, dim=-1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7e73NTPfZAF"
      },
      "source": [
        "attention = torch.einsum('b i j , b j d -> b i d', weight, v)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_cybnQafbGC",
        "outputId": "975f2d6f-843e-4344-8f54-1192c2061521"
      },
      "source": [
        "attention.size()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 1024, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBmOzD_lgtim"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}