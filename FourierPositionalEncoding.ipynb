{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FourierPositionalEncoding.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOF2l/+Qif20qk5lCcP9ajh"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JRlv5NNu82R"
      },
      "source": [
        "#I'm not sure why people makes their Fourier Positional Encoding so complicate and I'm not sure they are right. So here is my own version\n",
        "#I might be wrong, but hey coding is understanding (or trying)\n",
        "\n",
        "%%capture\n",
        "!pip install einops"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kAZU_oRwV8t"
      },
      "source": [
        "from torchvision.io import read_image\n",
        "from einops import rearrange, reduce\n",
        "import torch\n",
        "import math"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqKptW_gvVKu",
        "outputId": "75e0229d-568f-4ba3-b2be-02ca461e48b2"
      },
      "source": [
        "im = read_image('/content/224_224_image.jpg').to(torch.float)\n",
        "print('image size:',im.size())"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "image size: torch.Size([3, 224, 224])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCdzIlRowB1b",
        "outputId": "1acce3f5-2e64-4091-826e-f2db4292fc90"
      },
      "source": [
        "# Turn the image to black and white to reduce 3D dimensions to 2D dimension representing the spatial detail of the image \n",
        "black_and_white_image = reduce(im,'c h w -> h w', 'mean')\n",
        "print('black and white image:',black_and_white_image.size())"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "black and white image: torch.Size([224, 224])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9Q1RSEQIUgD",
        "outputId": "006ac068-8899-483a-a63a-4456483890f8"
      },
      "source": [
        "black_and_white_image"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[232.0000, 230.0000, 229.6667,  ..., 119.3333, 128.0000, 145.0000],\n",
              "        [226.0000, 229.0000, 231.6667,  ..., 122.0000, 129.0000, 146.0000],\n",
              "        [222.6667, 228.6667, 230.6667,  ..., 123.3333, 129.3333, 147.3333],\n",
              "        ...,\n",
              "        [139.0000, 137.6667, 138.0000,  ..., 110.0000, 118.6667, 113.3333],\n",
              "        [ 98.3333, 102.6667, 105.3333,  ..., 118.6667, 148.6667, 148.6667],\n",
              "        [ 60.0000,  82.0000,  96.3333,  ..., 118.6667, 139.0000, 137.0000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haHIe4pFvZxa"
      },
      "source": [
        "# create a function to normalise the image array between -1 and 1\n",
        "def normalisation(x):\n",
        "  x =  x/x.sum(0).expand_as(x) \n",
        "  x[torch.isnan(x)]=0   #if an entire column is zero, division by 0 will cause NaNs\n",
        "  x = 2*x - 1\n",
        "  return x"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVXN_m6HxCne"
      },
      "source": [
        "#Normalise the image\n",
        "normalised_image = normalisation(black_and_white_image)"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzFiba5D2S-S",
        "outputId": "3bc61913-ab84-4405-ec88-9016de685534"
      },
      "source": [
        "normalised_image"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9911, -0.9911, -0.9911,  ..., -0.9911, -0.9911, -0.9911],\n",
              "        [-0.9911, -0.9911, -0.9911,  ..., -0.9911, -0.9911, -0.9911],\n",
              "        [-0.9911, -0.9911, -0.9911,  ..., -0.9911, -0.9911, -0.9911],\n",
              "        ...,\n",
              "        [-0.9911, -0.9911, -0.9911,  ..., -0.9911, -0.9911, -0.9911],\n",
              "        [-0.9910, -0.9910, -0.9910,  ..., -0.9911, -0.9911, -0.9911],\n",
              "        [-0.9910, -0.9910, -0.9910,  ..., -0.9911, -0.9911, -0.9911]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vK_wYlT2xF6M"
      },
      "source": [
        "#create a log splace tensor between 1 and pi/2\n",
        "fk_sin = torch.logspace(start=1, end=0.5*math.pi, steps=7, base=2)\n",
        "fk_cos = torch.logspace(start=1, end=0.5*math.pi, steps=7, base=2)\n",
        "pe = torch.zeros(224,224,7*2+1)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCcnsUzpxJLM"
      },
      "source": [
        "# Create a fourier positional encoding\n",
        "for j in range(224):\n",
        "  for i in range(224):\n",
        "    x = normalised_image[j][i]\n",
        "    sin = torch.sin(math.pi*x*fk_sin)\n",
        "    cos = torch.cos(math.pi*x*fk_cos)\n",
        "    fk = torch.cat((sin,cos))\n",
        "    fk_ = fk.tolist()\n",
        "    fk_.append(x.item())\n",
        "    fk = torch.tensor(fk_)\n",
        "    pe[j][i]=fk"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCNP1vsVzNxQ",
        "outputId": "644d7a45-bf42-4916-f427-09077e682304"
      },
      "source": [
        "pe.size()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([224, 224, 15])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0NJFrFeI_jx"
      },
      "source": [
        "#Flatten the pe array:\n",
        "pe = rearrange(pe,'h w f -> (h w) f')"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqtn1apfJS5R",
        "outputId": "1e116248-b386-431e-e036-40e931d1ed63"
      },
      "source": [
        "pe"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0558, -0.3604, -0.7326,  ..., -0.7212, -0.9847, -0.9911],\n",
              "        [ 0.0558, -0.3604, -0.7326,  ..., -0.7212, -0.9847, -0.9911],\n",
              "        [ 0.0558, -0.3604, -0.7326,  ..., -0.7212, -0.9847, -0.9911],\n",
              "        ...,\n",
              "        [ 0.0561, -0.3601, -0.7323,  ..., -0.7209, -0.9846, -0.9911],\n",
              "        [ 0.0560, -0.3601, -0.7324,  ..., -0.7210, -0.9847, -0.9911],\n",
              "        [ 0.0560, -0.3601, -0.7324,  ..., -0.7210, -0.9847, -0.9911]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgOBn_lSJUn9",
        "outputId": "097ebcc6-f469-40be-aa36-7025b8635673"
      },
      "source": [
        "pe.size()"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50176, 15])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRMJQ01-A0ZQ",
        "outputId": "c182baca-2f1e-487e-f4f9-84d0e3f47c67"
      },
      "source": [
        "#Explaination:\n",
        "# Along this dimension, there are 50176 inputs, which is equivalent to the flatten image array of 224 x 224\n",
        "# Within each input, there are 15 values, these 15 values corresponds to 2K + 1. Where K is the number of bands. In this example, a value of 7 was used. The reason you times K by 2 is because\n",
        "#you need to calculate the cos and sin value for each band frequency. You add 1 to the end because you need to concat the normalised input with the 14 fourier values (7*2+1 = 15)\n",
        "print('Number of positional encoding values for each input:',pe.size(1))"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of positional encoding values for each input: 15\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}