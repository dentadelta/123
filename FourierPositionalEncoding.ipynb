{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FourierPositionalEncoding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNHUq0D0OsR5jCbCbqYzhsr"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9wDarB2SY4t"
      },
      "source": [
        "%%capture\n",
        "!pip install einops transformers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7cc2b1cOJN5"
      },
      "source": [
        "from torchvision.io import read_image\n",
        "from einops import rearrange, reduce\n",
        "import torch\n",
        "import math\n",
        "from torchvision.transforms import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import GPT2Model, GPT2Config"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddwo7hq9ONmP",
        "outputId": "d22be6bd-0dd4-45fb-fcde-55707d55bd66"
      },
      "source": [
        "Batch_Size = 5\n",
        "Image_Height = 224\n",
        "Image_Width = 224\n",
        "K = 7\n",
        "dmodel = 512  \n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('device type is:',device)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device type is: cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj4X5AMGOR1N"
      },
      "source": [
        "def normaliseImage(bm):\n",
        "  #Normalise the image:\n",
        "  mean, std = bm.mean([2,3]), bm.std([2,3])\n",
        "  i = 0\n",
        "  for m,s in zip(mean,std):\n",
        "      normaliser = transforms.Normalize(m, s)\n",
        "      normalised_image = normaliser(bm[i])\n",
        "      scale = max(abs(normalised_image.max()),abs(normalised_image.min()))\n",
        "      bm[i] = normalised_image/scale\n",
        "      i += 1\n",
        "  return reduce(bm,'b c h w -> b h w', 'mean')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPwB5JhoO5zA"
      },
      "source": [
        "def fourier_encoder(batch_image,K=7):\n",
        "    m = 256    \n",
        "    pe = torch.rand(batch_image.size(0),batch_image.size(1),batch_image.size(2),4*K + 1).to(device)\n",
        "    band_frequency = torch.logspace(start=1, end= m/2,steps=K,base=2,dtype=torch.float64).to(device)\n",
        "    x_normalised_coordinate = torch.linspace(start=-1, end=1,steps=batch_image.size(1),dtype=torch.float64).to(device)\n",
        "    y_normalised_coordinate = torch.linspace(start=-1, end=1,steps=batch_image.size(2),dtype=torch.float64).to(device)\n",
        "    b = 0\n",
        "    for b in range(batch_image.size(0)):\n",
        "        x = 0\n",
        "        for i in x_normalised_coordinate:\n",
        "            angle_x = i*math.pi*band_frequency\n",
        "            angle_y = torch.einsum('i,j -> ij',y_normalised_coordinate,band_frequency)*math.pi\n",
        "            pe[b][x][:,-1] = batch_image[b][x]\n",
        "            pe[b][x][:,0:2*K:2] = angle_x.sin()\n",
        "            pe[b][x][:,1:2*K:2] = angle_x.cos()\n",
        "            pe[b][x][:,2*K:4*K:2] = angle_y.sin()\n",
        "            pe[b][x][:,2*K + 1:4*K:2] = angle_y.cos()\n",
        "            x += 1\n",
        "    return rearrange(pe,'b h w c -> b (h w) c')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tu7mk5axO15N",
        "outputId": "d181ba61-50eb-4f60-adaf-253dd2edb566"
      },
      "source": [
        "# Create a fake batch image. Will use actual images later to see if the network can learn.For now, lets create the model first\n",
        "batch_image = torch.rand(Batch_Size,3,Image_Height,Image_Width).to(device)\n",
        "print(batch_image.size())\n",
        "#If you dont have a GPU then this operation can take awhile. A GPU performs about 30 times faster than a CPU so you should see the result instantaneously\n",
        "batch_image = normaliseImage(batch_image)\n",
        "batch_image = fourier_encoder(batch_image,K)\n",
        "latent_array = torch.rand(Batch_Size,32,32).to(device)\n",
        "latent_array = fourier_encoder(latent_array,K)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3, 224, 224])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MshZEJI_POlo"
      },
      "source": [
        "to_q = torch.nn.Linear(K*4+1,dmodel).to(device)  #29 = 4*4 + 1; 512 is the dmodel dimension\n",
        "to_k = torch.nn.Linear(K*4+1,dmodel).to(device)\n",
        "to_v = torch.nn.Linear(K*4+1,dmodel).to(device)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nie2u6-1ekV3"
      },
      "source": [
        "q = to_q(latent_array)\n",
        "k = to_k(batch_image)\n",
        "v = to_v(batch_image)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RU3ZfbSfBQP"
      },
      "source": [
        "I = torch.einsum('b i d , b j d -> b i j', q, k)/dmodel**0.5"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZTQ-fc-fW-h"
      },
      "source": [
        "weight = torch.nn.functional.softmax(I, dim=-1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7e73NTPfZAF"
      },
      "source": [
        "attention = torch.einsum('b i j , b j d -> b i d', weight, v)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_cybnQafbGC",
        "outputId": "23ebd0d1-ad9f-40c8-f138-4a7dec83163d"
      },
      "source": [
        "attention.size()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 1024, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBmOzD_lgtim"
      },
      "source": [
        "config = GPT2Config()\n",
        "config.add_cross_attention = True\n",
        "config.n_head = 8 \n",
        "config.n_layer = 8 \n",
        "config.n_embd = 512"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4pqb3KN-KCf"
      },
      "source": [
        "latent_transformer = GPT2Model(config).to(device)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpsMG4SJGlD5"
      },
      "source": [
        "CAPTION_LENGTH = 128\n",
        "random_text_input = torch.randint(config.vocab_size, (Batch_Size,CAPTION_LENGTH)).to(device)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsVWTWLECcKA"
      },
      "source": [
        "output = latent_transformer(input_ids=random_text_input,\n",
        "                            encoder_hidden_states=attention)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2c8GYVwCeu-"
      },
      "source": [
        "output_last_hidden_state = output['last_hidden_state'].permute(0,2,1)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29siTz4NFp6T"
      },
      "source": [
        "ffn = torch.nn.Linear(CAPTION_LENGTH,1024)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQjeen4cGDTR"
      },
      "source": [
        "output_block_1 = ffn(output_last_hidden_state).permute(0,2,1)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxZwyBhCGjKD",
        "outputId": "8fa4b212-35d0-4fb5-a36d-e9fd623ff5f0"
      },
      "source": [
        "output_block_1.size()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 1024, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOTO75ceQoDf"
      },
      "source": [
        "#Now repeat the same process 8 more times with the same sharing weight???\n",
        "#Not sure if I fed in the correct information into the latent_transformer though. Need to do more research\n",
        "#Also, I think I need to use the GPT2LTModel to load the pretrained model; and also to train the entire input_ids sequence. GPT2Model only train one generating sequence step each time."
      ],
      "execution_count": 46,
      "outputs": []
    }
  ]
}