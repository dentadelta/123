{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageCaptioning_Demo.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP/PLaKxtGZKzAFU6JUEYR8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5FCS-w_PM5u"
      },
      "source": [
        "# Specify your image_path right here\n",
        "url = 'https://zenherald.com/wp-content/uploads/2020/10/Modern-day-Viking-e1618564239690.webp'"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Ac5emPKRUX5D"
      },
      "source": [
        "#@title Run this cell to download necessary codes - Only need to run once\n",
        "%%capture\n",
        "!pip install transformers\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "import torchvision as tv\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer\n",
        "import requests\n",
        "model = torch.hub.load('saahiluppal/catr', 'v3', pretrained=True)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "start_token = tokenizer.convert_tokens_to_ids(tokenizer._cls_token)\n",
        "end_token = tokenizer.convert_tokens_to_ids(tokenizer._sep_token)\n",
        "\n",
        "def under_max(image):\n",
        "    if image.mode != 'RGB':\n",
        "        image = image.convert(\"RGB\")\n",
        "\n",
        "    shape = np.array(image.size, dtype=np.float)\n",
        "    long_dim = max(shape)\n",
        "    scale = 299 / long_dim\n",
        "\n",
        "    new_shape = (shape * scale).astype(int)\n",
        "    image = image.resize(new_shape)\n",
        "\n",
        "    return image\n",
        "\n",
        "val_transform = tv.transforms.Compose([\n",
        "    tv.transforms.Lambda(under_max),\n",
        "    tv.transforms.ToTensor(),\n",
        "    tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "def create_caption_and_mask(start_token, max_length):\n",
        "    caption_template = torch.zeros((1, max_length), dtype=torch.long)\n",
        "    mask_template = torch.ones((1, max_length), dtype=torch.bool)\n",
        "\n",
        "    caption_template[:, 0] = start_token\n",
        "    mask_template[:, 0] = False\n",
        "\n",
        "    return caption_template, mask_template\n",
        "  \n",
        "caption, cap_mask = create_caption_and_mask(start_token, 128)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "0kZCYUBuQTXp",
        "outputId": "ca6eacb2-3602-4d92-b767-e7eb2b1c0367"
      },
      "source": [
        "#@title Run this cell to caption image. Rerun this cell if you change the image url\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "image = val_transform(image)\n",
        "image = image.unsqueeze(0)\n",
        "@torch.no_grad()\n",
        "def evaluate():\n",
        "    model.eval()\n",
        "    for i in range(128 - 1):\n",
        "        predictions = model(image, caption, cap_mask)\n",
        "        predictions = predictions[:, i, :]\n",
        "        predicted_id = torch.argmax(predictions, axis=-1)\n",
        "\n",
        "        if predicted_id[0] == 102:\n",
        "            return caption\n",
        "\n",
        "        caption[:, i+1] = predicted_id[0]\n",
        "        cap_mask[:, i+1] = False\n",
        "\n",
        "    return caption\n",
        "\n",
        "output = evaluate()\n",
        "result = tokenizer.decode(output[0].tolist(), skip_special_tokens=True)\n",
        "print(result.capitalize())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A man with a mask on his head is holding a horse.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}